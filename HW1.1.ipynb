{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read files\n",
    "df_raw = pd.read_csv(r'C:\\Users\\Abraham\\MSBA\\Text\\HW1\\Train_rev1.csv')\n",
    "df_train = df_raw.sample(2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train[['Id','FullDescription','SalaryNormalized']]\n",
    "df_train['FullDescription'] = df_train['FullDescription'].map(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dt = {}\n",
    "\n",
    "def pos_count(desc):\n",
    "    tokens = re.findall('\\w+', desc)\n",
    "    tokenlist = nltk.pos_tag(tokens)\n",
    "    \n",
    "    for t in tokenlist:\n",
    "        pos = t[1]\n",
    "        if pos in pos_dt:\n",
    "            pos_dt[pos] += 1\n",
    "        else:\n",
    "            pos_dt[pos] = 1\n",
    "    \n",
    "    return desc\n",
    "\n",
    "df_train['FullDescription'].map(pos_count)\n",
    "\n",
    "pos_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "pos_nostop_dt = {}\n",
    "\n",
    "def pos_nostop_count(desc):\n",
    "    tokens = re.findall('\\w+', desc)\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words]\n",
    "    \n",
    "    tokenlist = nltk.pos_tag(filtered_tokens)\n",
    "    \n",
    "    for t in tokenlist:\n",
    "        pos = t[1]\n",
    "        if pos in pos_nostop_dt:\n",
    "            pos_nostop_dt[pos] += 1\n",
    "        else:\n",
    "            pos_nostop_dt[pos] = 1\n",
    "    \n",
    "    return desc\n",
    "\n",
    "df_train['FullDescription'].map(pos_nostop_count)\n",
    "\n",
    "pos_nostop_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series(pos_dt).sort_values(ascending=False)[0:5].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Series(pos_nostop_dt).sort_values(ascending=False)[0:5].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = df_train['FullDescription'].str.cat(sep = ' ') #pos = a.decode('utf-8')\n",
    "s = re.findall('\\w+', a)\n",
    "s = Series(s)\n",
    "\n",
    "df_words = DataFrame(s.value_counts())\n",
    "df_words = df_words.reset_index()\n",
    "df_words.columns = ['Word','Counts']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# topcount = df_words.iloc[0]['Counts']\n",
    "# zipf_list = []\n",
    "\n",
    "# for f in range(1,len(df_words)):\n",
    "#     zipf_list.append(topcount/f)\n",
    "\n",
    "# Series(zipf_list)\n",
    "    \n",
    "# df_words['Zipf'] = Series(zipf_list)\n",
    "\n",
    "# df_words['Counts'][0:50].plot(kind='bar')\n",
    "# df_words['Zipf'][0:50].plot(kind='line')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words['Rank'] = df_words['Counts'].rank(ascending=False)\n",
    "df_words['LogCount'] = log(df_words['Counts']/df_words.iloc[len(df_words)-1]['Counts'])\n",
    "df_words['LogRank'] = log(df_words['Rank'])\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(df_words['LogCount'],df_words['LogRank'])\n",
    "ax=sns.regplot(x='LogCount', y='LogRank', data=df_words,color='b',line_kws={'label':\"y={0:.1f}x+{1:.1f}\".format(slope,intercept)})\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = re.findall('\\w+', a)\n",
    "s = [w for w in s if not w in stop_words]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "s = Series(s).map(lemmatizer.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.value_counts()[0:10].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_raw.dropna().sample(2500)\n",
    "cutoff = df_train['SalaryNormalized'].quantile(0.75)\n",
    "\n",
    "df_train['HighSalary'] = 0\n",
    "df_train['HighSalary'][df_train['SalaryNormalized']>cutoff] = 1\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nbtrain = pd.get_dummies(df_train[['ContractType','ContractTime','Category']])\n",
    "\n",
    "#Cities where avg rent is >= 20% of avg income\n",
    "high_cities = ['London', 'Central London','The City','Brighton','Edinburgh','Bristol','Southampton','Portsmouth','Exeter'\\\n",
    "                 ,'Cardiff', 'Manchester', 'Birmingham', 'Leeds', 'Aberdeen', 'Glasgow', 'Newcastle', 'Sheffield', 'Liverpool', 'Hull']\n",
    "\n",
    "a = df_train['LocationNormalized']\n",
    "b = []\n",
    "\n",
    "for i in range(len(a)):\n",
    "    if a.iloc[i] in high_cities: \n",
    "        b.append(1)\n",
    "    else: b.append(0)\n",
    "\n",
    "df_nbtrain['ExpensiveCity'] = b\n",
    "df_nbtrain['HighSalary'] = df_train['HighSalary']\n",
    "df_nbtrain = df_nbtrain.drop(['ContractType_part_time','ContractTime_contract'], axis=1)\n",
    "df_nbtrain.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from patsy import dmatrices\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_column_names = list(df_nbtrain.columns.values)[:-1]\n",
    "\n",
    "formula = 'HighSalary ~ 0 + {}'.format(' + '.join(['Q(\"{}\")'.format(x) for x in dummy_column_names]))\n",
    "\n",
    "nbtrain, nbtest = train_test_split(df_nbtrain, test_size=0.2)\n",
    "    \n",
    "#Training Sets\n",
    "Ytrain, xtrain = dmatrices(formula, nbtrain, return_type='dataframe')\n",
    "ytrain = Ytrain['HighSalary'].values\n",
    "\n",
    "#Testing Set\n",
    "Ytest, xtest = dmatrices(formula, nbtest, return_type='dataframe')\n",
    "ytest = Ytest['HighSalary'].values\n",
    "\n",
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "prediction_train = model.predict(xtrain)\n",
    "print (\"Training\")\n",
    "print (metrics.accuracy_score(ytrain, prediction_train))\n",
    "\n",
    "print (\" \")\n",
    "print (\"Test\")\n",
    "prediction_test = model.predict(xtest)\n",
    "print (metrics.accuracy_score(ytest, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Full job description as the only predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import classification_report\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text = df_train[['FullDescription','HighSalary']]\n",
    "df_text['FullDescription'] = df_text['FullDescription'].dropna().str.lower().str.replace('\\d+', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test = vectorizer.fit(df_text['FullDescription'])\n",
    "# vectorizer = TfidfVectorizer(use_idf=False,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split Train and Test sets\n",
    "#Split descriptions from salary range\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_text['FullDescription'],\n",
    "                                                    df_text['HighSalary'],\n",
    "                                                    test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Like the document term matrix, but filled with 1's and 0's instead of TFIDF scores\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_test_counts = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit model on train data\n",
    "clf = BernoulliNB().fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predict using X_test data\n",
    "prediction = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percent correct overall\n",
    "metrics.accuracy_score(y_test, prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Row 1 is all the ones low salary\n",
    "#Column 1 is all the ones predicted low salary\n",
    "metrics.confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline accuracy = if we guessed 'No' for all of them\n",
    "1-y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
